{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509df442",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-14T21:19:47.262864Z",
     "iopub.status.busy": "2024-11-14T21:19:47.262465Z",
     "iopub.status.idle": "2024-11-14T21:19:48.030911Z",
     "shell.execute_reply": "2024-11-14T21:19:48.029849Z"
    },
    "papermill": {
     "duration": 0.776208,
     "end_time": "2024-11-14T21:19:48.033148",
     "exception": false,
     "start_time": "2024-11-14T21:19:47.256940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dianping/kg_final.txt\n",
      "/kaggle/input/dianping/ratings_final.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0655ab66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T21:19:48.041969Z",
     "iopub.status.busy": "2024-11-14T21:19:48.041538Z",
     "iopub.status.idle": "2024-11-14T21:19:48.050504Z",
     "shell.execute_reply": "2024-11-14T21:19:48.049594Z"
    },
    "papermill": {
     "duration": 0.015537,
     "end_time": "2024-11-14T21:19:48.052573",
     "exception": false,
     "start_time": "2024-11-14T21:19:48.037036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## NDGC & RMSE\n",
    "\n",
    "def dcg_k(r, k):\n",
    "    \"\"\" Discounted Cumulative Gain (DGC)  \n",
    "    Args:\n",
    "        r: True Ratings in Predicted Rank Order (1st element is top recommendation)\n",
    "        k: Number of results to consider\n",
    "    Returns:\n",
    "        DCG\n",
    "    \"\"\"\n",
    "  \n",
    "    r = np.asfarray(r)[:k]\n",
    "    return np.sum(2**r / np.log2(np.arange(2, r.size + 2)))      \n",
    "\n",
    "\n",
    "\n",
    "def ndcg_k(r, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain (NDCG)\n",
    "    Args:\n",
    "        r: True Ratings in Predicted Rank Order (1st element is top recommendation)\n",
    "        k: Number of results to consider\n",
    "    Returns:\n",
    "        NDCG\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_k(sorted(r, reverse=True), k)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_k(r, k) / dcg_max\n",
    "\n",
    "def mean_ndcg(rs):\n",
    "    \"\"\"Mean NDCG for all users\n",
    "    Args:\n",
    "        rs: Iterator / For each user: True Ratings in Predicted Rank Order\n",
    "    Returns:\n",
    "        Mean NDCG\n",
    "    \"\"\"\n",
    "    return np.mean([ndcg_k(r, len(r)) for r in rs])\n",
    "\n",
    "def rmse(y,h):\n",
    "    \"\"\"RMSE\n",
    "    Args:\n",
    "        y: real y\n",
    "        h: predicted y\n",
    "    Returns:\n",
    "        RMSE\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    h = np.array(h)\n",
    "\n",
    "    a = y-h\n",
    "\n",
    "    return np.sqrt(sum(a**2)/len(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b2dbc63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T21:19:48.060792Z",
     "iopub.status.busy": "2024-11-14T21:19:48.060396Z",
     "iopub.status.idle": "2024-11-14T21:19:48.069839Z",
     "shell.execute_reply": "2024-11-14T21:19:48.068924Z"
    },
    "papermill": {
     "duration": 0.015742,
     "end_time": "2024-11-14T21:19:48.071780",
     "exception": false,
     "start_time": "2024-11-14T21:19:48.056038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "def load_data():\n",
    "    logging.info(\"================== preparing data ===================\")\n",
    "    train_data, eval_data, test_data = load_rating()\n",
    "    # item_triple_sets = kg_propagation(args, kg, item_init_entity_set, args.item_triple_set_size, False)\n",
    "    return train_data, eval_data, test_data\n",
    "\n",
    "\n",
    "def load_rating():\n",
    "    rating_file = '/kaggle/input/dianping/ratings_final'\n",
    "    logging.info(\"load rating file: %s.npy\", rating_file)\n",
    "    if os.path.exists(rating_file + '.npy'):\n",
    "        rating_np = np.load(rating_file + '.npy')\n",
    "    else:\n",
    "        rating_np = np.loadtxt(rating_file + '.txt', dtype=np.int32)\n",
    "        # np.save(rating_file + '.npy', rating_np)\n",
    "    return dataset_split(rating_np)\n",
    "\n",
    "\n",
    "def dataset_split(rating_np):\n",
    "    logging.info(\"splitting dataset to 6:2:2 ...\")\n",
    "    # train:eval:test = 6:2:2\n",
    "    np.random.seed(37)\n",
    "    eval_ratio = 0.2\n",
    "    test_ratio = 0.2\n",
    "    n_ratings = rating_np.shape[0]\n",
    "    \n",
    "    eval_indices = np.random.choice(n_ratings, size=int(n_ratings * eval_ratio), replace=False)\n",
    "    left = set(range(n_ratings)) - set(eval_indices)\n",
    "    test_indices = np.random.choice(list(left), size=int(n_ratings * test_ratio), replace=False)\n",
    "    train_indices = list(left - set(test_indices))\n",
    "    \n",
    "    # user_init_entity_set, item_init_entity_set = collaboration_propagation(rating_np, train_indices)\n",
    "    \n",
    "    # train_indices = [i for i in train_indices if rating_np[i][0] in user_init_entity_set.keys()]\n",
    "    # eval_indices = [i for i in eval_indices if rating_np[i][0] in user_init_entity_set.keys()]\n",
    "    # test_indices = [i for i in test_indices if rating_np[i][0] in user_init_entity_set.keys()]\n",
    "    train_data = rating_np[train_indices]\n",
    "    eval_data = rating_np[eval_indices]\n",
    "    test_data = rating_np[test_indices]\n",
    "    \n",
    "    return train_data, eval_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c2b723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T21:19:48.080110Z",
     "iopub.status.busy": "2024-11-14T21:19:48.079791Z",
     "iopub.status.idle": "2024-11-14T21:20:10.943451Z",
     "shell.execute_reply": "2024-11-14T21:20:10.942483Z"
    },
    "papermill": {
     "duration": 22.870439,
     "end_time": "2024-11-14T21:20:10.945812",
     "exception": false,
     "start_time": "2024-11-14T21:19:48.075373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, eval, test = load_data()\n",
    "\n",
    "train = train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90350a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T21:20:10.954465Z",
     "iopub.status.busy": "2024-11-14T21:20:10.954157Z",
     "iopub.status.idle": "2024-11-14T21:20:10.963836Z",
     "shell.execute_reply": "2024-11-14T21:20:10.963094Z"
    },
    "papermill": {
     "duration": 0.016239,
     "end_time": "2024-11-14T21:20:10.965819",
     "exception": false,
     "start_time": "2024-11-14T21:20:10.949580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def matrix_factorization(train, num_users, num_foods, latent_dim=10, lr=0.01, reg=0.1, epochs=100):\n",
    "    U = np.random.normal(scale=1.0/latent_dim, size=(num_users, latent_dim))\n",
    "    F = np.random.normal(scale=1.0/latent_dim, size=(num_foods, latent_dim))\n",
    "\n",
    "    # Training using SGD\n",
    "    for epoch in range(epochs):\n",
    "        np.random.shuffle(train) \n",
    "\n",
    "        for user_id, food_id, rating in train:\n",
    "            user_id = int(user_id)  # Ensure indexing is an integer\n",
    "            food_id = int(food_id)\n",
    "\n",
    "            pred_rating = np.dot(U[user_id], F[food_id])\n",
    "            error = rating - pred_rating\n",
    "\n",
    "            U[user_id] += lr * (error * F[food_id] - reg * U[user_id])\n",
    "            F[food_id] += lr * (error * U[user_id] - reg * F[food_id])\n",
    "\n",
    "        loss = 0\n",
    "        for user_id, food_id, rating in train:\n",
    "            user_id = int(user_id)\n",
    "            food_id = int(food_id)\n",
    "            pred_rating = np.dot(U[user_id], F[food_id])\n",
    "            error = rating - pred_rating\n",
    "            loss += error**2 + reg * (np.linalg.norm(U[user_id])**2 + np.linalg.norm(F[food_id])**2)\n",
    "\n",
    "        loss /= len(train)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return U, F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfcc4412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T21:20:10.974044Z",
     "iopub.status.busy": "2024-11-14T21:20:10.973741Z",
     "iopub.status.idle": "2024-11-14T21:20:14.965616Z",
     "shell.execute_reply": "2024-11-14T21:20:14.964617Z"
    },
    "papermill": {
     "duration": 3.998471,
     "end_time": "2024-11-14T21:20:14.967821",
     "exception": false,
     "start_time": "2024-11-14T21:20:10.969350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.5163\n",
      "Epoch 2/100, Loss: 0.5141\n",
      "Epoch 3/100, Loss: 0.5121\n",
      "Epoch 4/100, Loss: 0.5103\n",
      "Epoch 5/100, Loss: 0.5086\n",
      "Epoch 6/100, Loss: 0.5070\n",
      "Epoch 7/100, Loss: 0.5055\n",
      "Epoch 8/100, Loss: 0.5041\n",
      "Epoch 9/100, Loss: 0.5027\n",
      "Epoch 10/100, Loss: 0.5014\n",
      "Epoch 11/100, Loss: 0.5001\n",
      "Epoch 12/100, Loss: 0.4988\n",
      "Epoch 13/100, Loss: 0.4975\n",
      "Epoch 14/100, Loss: 0.4962\n",
      "Epoch 15/100, Loss: 0.4948\n",
      "Epoch 16/100, Loss: 0.4935\n",
      "Epoch 17/100, Loss: 0.4922\n",
      "Epoch 18/100, Loss: 0.4908\n",
      "Epoch 19/100, Loss: 0.4894\n",
      "Epoch 20/100, Loss: 0.4880\n",
      "Epoch 21/100, Loss: 0.4865\n",
      "Epoch 22/100, Loss: 0.4850\n",
      "Epoch 23/100, Loss: 0.4835\n",
      "Epoch 24/100, Loss: 0.4819\n",
      "Epoch 25/100, Loss: 0.4802\n",
      "Epoch 26/100, Loss: 0.4785\n",
      "Epoch 27/100, Loss: 0.4767\n",
      "Epoch 28/100, Loss: 0.4749\n",
      "Epoch 29/100, Loss: 0.4730\n",
      "Epoch 30/100, Loss: 0.4710\n",
      "Epoch 31/100, Loss: 0.4689\n",
      "Epoch 32/100, Loss: 0.4668\n",
      "Epoch 33/100, Loss: 0.4646\n",
      "Epoch 34/100, Loss: 0.4623\n",
      "Epoch 35/100, Loss: 0.4599\n",
      "Epoch 36/100, Loss: 0.4574\n",
      "Epoch 37/100, Loss: 0.4548\n",
      "Epoch 38/100, Loss: 0.4521\n",
      "Epoch 39/100, Loss: 0.4494\n",
      "Epoch 40/100, Loss: 0.4465\n",
      "Epoch 41/100, Loss: 0.4435\n",
      "Epoch 42/100, Loss: 0.4405\n",
      "Epoch 43/100, Loss: 0.4373\n",
      "Epoch 44/100, Loss: 0.4340\n",
      "Epoch 45/100, Loss: 0.4307\n",
      "Epoch 46/100, Loss: 0.4273\n",
      "Epoch 47/100, Loss: 0.4238\n",
      "Epoch 48/100, Loss: 0.4202\n",
      "Epoch 49/100, Loss: 0.4165\n",
      "Epoch 50/100, Loss: 0.4128\n",
      "Epoch 51/100, Loss: 0.4090\n",
      "Epoch 52/100, Loss: 0.4051\n",
      "Epoch 53/100, Loss: 0.4012\n",
      "Epoch 54/100, Loss: 0.3973\n",
      "Epoch 55/100, Loss: 0.3933\n",
      "Epoch 56/100, Loss: 0.3893\n",
      "Epoch 57/100, Loss: 0.3853\n",
      "Epoch 58/100, Loss: 0.3812\n",
      "Epoch 59/100, Loss: 0.3772\n",
      "Epoch 60/100, Loss: 0.3731\n",
      "Epoch 61/100, Loss: 0.3691\n",
      "Epoch 62/100, Loss: 0.3651\n",
      "Epoch 63/100, Loss: 0.3611\n",
      "Epoch 64/100, Loss: 0.3571\n",
      "Epoch 65/100, Loss: 0.3531\n",
      "Epoch 66/100, Loss: 0.3492\n",
      "Epoch 67/100, Loss: 0.3453\n",
      "Epoch 68/100, Loss: 0.3415\n",
      "Epoch 69/100, Loss: 0.3377\n",
      "Epoch 70/100, Loss: 0.3340\n",
      "Epoch 71/100, Loss: 0.3303\n",
      "Epoch 72/100, Loss: 0.3267\n",
      "Epoch 73/100, Loss: 0.3231\n",
      "Epoch 74/100, Loss: 0.3195\n",
      "Epoch 75/100, Loss: 0.3161\n",
      "Epoch 76/100, Loss: 0.3127\n",
      "Epoch 77/100, Loss: 0.3093\n",
      "Epoch 78/100, Loss: 0.3060\n",
      "Epoch 79/100, Loss: 0.3028\n",
      "Epoch 80/100, Loss: 0.2996\n",
      "Epoch 81/100, Loss: 0.2965\n",
      "Epoch 82/100, Loss: 0.2935\n",
      "Epoch 83/100, Loss: 0.2905\n",
      "Epoch 84/100, Loss: 0.2876\n",
      "Epoch 85/100, Loss: 0.2847\n",
      "Epoch 86/100, Loss: 0.2819\n",
      "Epoch 87/100, Loss: 0.2792\n",
      "Epoch 88/100, Loss: 0.2765\n",
      "Epoch 89/100, Loss: 0.2739\n",
      "Epoch 90/100, Loss: 0.2713\n",
      "Epoch 91/100, Loss: 0.2688\n",
      "Epoch 92/100, Loss: 0.2664\n",
      "Epoch 93/100, Loss: 0.2640\n",
      "Epoch 94/100, Loss: 0.2617\n",
      "Epoch 95/100, Loss: 0.2594\n",
      "Epoch 96/100, Loss: 0.2572\n",
      "Epoch 97/100, Loss: 0.2550\n",
      "Epoch 98/100, Loss: 0.2529\n",
      "Epoch 99/100, Loss: 0.2508\n",
      "Epoch 100/100, Loss: 0.2488\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# train = np.array([\n",
    "#     [0, 0, 5],\n",
    "#     [0, 1, 3],\n",
    "#     [1, 0, 4],\n",
    "#     [1, 2, 1],\n",
    "#     # ... (user_id, food_id, rating)\n",
    "# ])\n",
    "num_users = int(np.max(train[:, 0]) + 1)\n",
    "num_foods = int(np.max(train[:, 1]) + 1)\n",
    "latent_dim = 10\n",
    "U, F = matrix_factorization(train, num_users, num_foods, latent_dim=latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde6d798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T21:20:14.980412Z",
     "iopub.status.busy": "2024-11-14T21:20:14.979859Z",
     "iopub.status.idle": "2024-11-14T21:20:25.090327Z",
     "shell.execute_reply": "2024-11-14T21:20:25.089378Z"
    },
    "papermill": {
     "duration": 10.120059,
     "end_time": "2024-11-14T21:20:25.092977",
     "exception": false,
     "start_time": "2024-11-14T21:20:14.972918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(U, F, user_id, food_id, default_rating=0):\n",
    "    if user_id < 0 or user_id >= U.shape[0] or food_id < 0 or food_id >= F.shape[0]:\n",
    "        return default_rating\n",
    "    return np.dot(U[user_id], F[food_id])\n",
    "\n",
    "\n",
    "dev_y_pred = [infer(U, F, int(user_id), int(food_id)) for user_id, food_id, _ in eval]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b883062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T20:48:11.425637Z",
     "iopub.status.busy": "2024-11-14T20:48:11.424983Z",
     "iopub.status.idle": "2024-11-14T20:48:11.431317Z",
     "shell.execute_reply": "2024-11-14T20:48:11.430419Z",
     "shell.execute_reply.started": "2024-11-14T20:48:11.425597Z"
    },
    "papermill": {
     "duration": 0.004758,
     "end_time": "2024-11-14T21:20:25.102881",
     "exception": false,
     "start_time": "2024-11-14T21:20:25.098123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833ba08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T21:20:25.114359Z",
     "iopub.status.busy": "2024-11-14T21:20:25.113920Z",
     "iopub.status.idle": "2024-11-15T08:14:40.443913Z",
     "shell.execute_reply": "2024-11-15T08:14:40.442883Z"
    },
    "papermill": {
     "duration": 39255.345079,
     "end_time": "2024-11-15T08:14:40.452813",
     "exception": false,
     "start_time": "2024-11-14T21:20:25.107734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.5184\n",
      "Epoch 2/100, Loss: 0.5158\n",
      "Epoch 3/100, Loss: 0.5135\n",
      "Epoch 4/100, Loss: 0.5115\n",
      "Epoch 5/100, Loss: 0.5097\n",
      "Epoch 6/100, Loss: 0.5080\n",
      "Epoch 7/100, Loss: 0.5064\n",
      "Epoch 8/100, Loss: 0.5049\n",
      "Epoch 9/100, Loss: 0.5034\n",
      "Epoch 10/100, Loss: 0.5021\n",
      "Epoch 11/100, Loss: 0.5007\n",
      "Epoch 12/100, Loss: 0.4994\n",
      "Epoch 13/100, Loss: 0.4981\n",
      "Epoch 14/100, Loss: 0.4968\n",
      "Epoch 15/100, Loss: 0.4956\n",
      "Epoch 16/100, Loss: 0.4943\n",
      "Epoch 17/100, Loss: 0.4930\n",
      "Epoch 18/100, Loss: 0.4917\n",
      "Epoch 19/100, Loss: 0.4904\n",
      "Epoch 20/100, Loss: 0.4890\n",
      "Epoch 21/100, Loss: 0.4876\n",
      "Epoch 22/100, Loss: 0.4862\n",
      "Epoch 23/100, Loss: 0.4848\n",
      "Epoch 24/100, Loss: 0.4833\n",
      "Epoch 25/100, Loss: 0.4817\n",
      "Epoch 26/100, Loss: 0.4802\n",
      "Epoch 27/100, Loss: 0.4785\n",
      "Epoch 28/100, Loss: 0.4769\n",
      "Epoch 29/100, Loss: 0.4751\n",
      "Epoch 30/100, Loss: 0.4733\n",
      "Epoch 31/100, Loss: 0.4714\n",
      "Epoch 32/100, Loss: 0.4695\n",
      "Epoch 33/100, Loss: 0.4675\n",
      "Epoch 34/100, Loss: 0.4654\n",
      "Epoch 35/100, Loss: 0.4632\n",
      "Epoch 36/100, Loss: 0.4610\n",
      "Epoch 37/100, Loss: 0.4586\n",
      "Epoch 38/100, Loss: 0.4562\n",
      "Epoch 39/100, Loss: 0.4537\n",
      "Epoch 40/100, Loss: 0.4511\n",
      "Epoch 41/100, Loss: 0.4485\n",
      "Epoch 42/100, Loss: 0.4457\n",
      "Epoch 43/100, Loss: 0.4428\n",
      "Epoch 44/100, Loss: 0.4399\n",
      "Epoch 45/100, Loss: 0.4368\n",
      "Epoch 46/100, Loss: 0.4337\n",
      "Epoch 47/100, Loss: 0.4305\n",
      "Epoch 48/100, Loss: 0.4272\n",
      "Epoch 49/100, Loss: 0.4238\n",
      "Epoch 50/100, Loss: 0.4203\n",
      "Epoch 51/100, Loss: 0.4168\n",
      "Epoch 52/100, Loss: 0.4132\n",
      "Epoch 53/100, Loss: 0.4095\n",
      "Epoch 54/100, Loss: 0.4058\n",
      "Epoch 55/100, Loss: 0.4020\n",
      "Epoch 56/100, Loss: 0.3982\n",
      "Epoch 57/100, Loss: 0.3943\n",
      "Epoch 58/100, Loss: 0.3904\n",
      "Epoch 59/100, Loss: 0.3865\n",
      "Epoch 60/100, Loss: 0.3825\n",
      "Epoch 61/100, Loss: 0.3785\n",
      "Epoch 62/100, Loss: 0.3746\n",
      "Epoch 63/100, Loss: 0.3706\n",
      "Epoch 64/100, Loss: 0.3666\n",
      "Epoch 65/100, Loss: 0.3627\n",
      "Epoch 66/100, Loss: 0.3588\n",
      "Epoch 67/100, Loss: 0.3549\n",
      "Epoch 68/100, Loss: 0.3510\n",
      "Epoch 69/100, Loss: 0.3471\n",
      "Epoch 70/100, Loss: 0.3433\n",
      "Epoch 71/100, Loss: 0.3395\n",
      "Epoch 72/100, Loss: 0.3358\n",
      "Epoch 73/100, Loss: 0.3321\n",
      "Epoch 74/100, Loss: 0.3285\n",
      "Epoch 75/100, Loss: 0.3249\n",
      "Epoch 76/100, Loss: 0.3214\n",
      "Epoch 77/100, Loss: 0.3179\n",
      "Epoch 78/100, Loss: 0.3145\n",
      "Epoch 79/100, Loss: 0.3112\n",
      "Epoch 80/100, Loss: 0.3079\n",
      "Epoch 81/100, Loss: 0.3047\n",
      "Epoch 82/100, Loss: 0.3015\n",
      "Epoch 83/100, Loss: 0.2984\n",
      "Epoch 84/100, Loss: 0.2953\n",
      "Epoch 85/100, Loss: 0.2923\n",
      "Epoch 86/100, Loss: 0.2894\n",
      "Epoch 87/100, Loss: 0.2866\n",
      "Epoch 88/100, Loss: 0.2837\n",
      "Epoch 89/100, Loss: 0.2810\n",
      "Epoch 90/100, Loss: 0.2783\n",
      "Epoch 91/100, Loss: 0.2757\n",
      "Epoch 92/100, Loss: 0.2731\n",
      "Epoch 93/100, Loss: 0.2706\n",
      "Epoch 94/100, Loss: 0.2682\n",
      "Epoch 95/100, Loss: 0.2658\n",
      "Epoch 96/100, Loss: 0.2634\n",
      "Epoch 97/100, Loss: 0.2612\n",
      "Epoch 98/100, Loss: 0.2589\n",
      "Epoch 99/100, Loss: 0.2567\n",
      "Epoch 100/100, Loss: 0.2546\n",
      "New best model with NDCG: 0.9596, RMSE: 0.7074\n",
      "\n",
      "Final evaluation on the test set:\n",
      "Test RMSE: 0.7070\n",
      "Mean Test NDCG@10: 0.9596\n",
      "Best parameters: {'latent_dim': 10, 'lr': 0.01, 'reg': 0.1, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "def parameter_tuning(train, eval_set, test_set, latent_dims=[10], lrs=[0.01], regs=[0.1], epochs=100):\n",
    "    best_model = None\n",
    "    best_score = -np.inf  # Track the highest NDCG score\n",
    "    best_params = {}\n",
    "    \n",
    "    # Grid search over parameter combinations\n",
    "    for latent_dim in latent_dims:\n",
    "        for lr in lrs:\n",
    "            for reg in regs:\n",
    "                # Train matrix factorization model\n",
    "                U, F = matrix_factorization(train, num_users=np.max(train[:, 0]) + 1,\n",
    "                                            num_foods=np.max(train[:, 1]) + 1,\n",
    "                                            latent_dim=latent_dim, lr=lr, reg=reg, epochs=epochs)\n",
    "                \n",
    "                # Evaluate on dev set (assumes dev has the same structure as train)\n",
    "                dev_y_true = [rating for _, _, rating in eval_set]\n",
    "                dev_y_pred = [infer(U, F, int(user_id), int(food_id)) for user_id, food_id, _ in eval_set]\n",
    "                dev_rmse = rmse(dev_y_true, dev_y_pred)\n",
    "                \n",
    "                # Calculate NDCG on eval set\n",
    "                # Group eval_set by user and calculate NDCG per user\n",
    "                eval_users = np.unique(eval_set[:, 0])\n",
    "                ndcg_scores = []\n",
    "                \n",
    "                for user_id in eval_users:\n",
    "                    user_ratings = eval_set[eval_set[:, 0] == user_id]\n",
    "                    relevance = [rating for _, _, rating in user_ratings]\n",
    "                    preds = [infer(U, F, int(user_id), int(food_id)) for _, food_id, _ in user_ratings]\n",
    "                    \n",
    "                    # Sort predictions by relevance\n",
    "                    sorted_indices = np.argsort(preds)[::-1]\n",
    "                    sorted_relevance = [relevance[i] for i in sorted_indices]\n",
    "                    \n",
    "                    # Calculate NDCG for this user\n",
    "                    ndcg_scores.append(ndcg_k(sorted_relevance, k=10))\n",
    "                \n",
    "                mean_ndcg_score = np.mean(ndcg_scores)\n",
    "                \n",
    "                # Check if this model is the best one based on NDCG (or RMSE if preferred)\n",
    "                if mean_ndcg_score > best_score:\n",
    "                    best_score = mean_ndcg_score\n",
    "                    best_model = (U, F)\n",
    "                    best_params = {'latent_dim': latent_dim, 'lr': lr, 'reg': reg, 'epochs': epochs}\n",
    "                    print(f\"New best model with NDCG: {mean_ndcg_score:.4f}, RMSE: {dev_rmse:.4f}\")\n",
    "\n",
    "    # Final evaluation on the test set\n",
    "    U, F = best_model\n",
    "    test_y_true = [rating for _, _, rating in test_set]\n",
    "    test_y_pred = [infer(U, F, int(user_id), int(food_id)) for user_id, food_id, _ in test_set]\n",
    "    test_rmse = rmse(test_y_true, test_y_pred)\n",
    "    \n",
    "    # Group test set by user and calculate mean NDCG per user\n",
    "    test_users = np.unique(test_set[:, 0])\n",
    "    test_ndcg_scores = []\n",
    "\n",
    "    for user_id in test_users:\n",
    "        user_ratings = test_set[test_set[:, 0] == user_id]\n",
    "        relevance = [rating for _, _, rating in user_ratings]\n",
    "        preds = [infer(U, F, int(user_id), int(food_id)) for _, food_id, _ in user_ratings]\n",
    "\n",
    "        sorted_indices = np.argsort(preds)[::-1]\n",
    "        sorted_relevance = [relevance[i] for i in sorted_indices]\n",
    "        test_ndcg_scores.append(ndcg_k(sorted_relevance, k=10))\n",
    "\n",
    "    mean_test_ndcg = np.mean(test_ndcg_scores)\n",
    "\n",
    "    print(\"\\nFinal evaluation on the test set:\")\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"Mean Test NDCG@10: {mean_test_ndcg:.4f}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "parameter_tuning(train, eval, test)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6077558,
     "sourceId": 9894893,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39296.249584,
   "end_time": "2024-11-15T08:14:40.777124",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-14T21:19:44.527540",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
